{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data Sample:\n",
      "                                                Name  \\\n",
      "0                                How to Learn Online   \n",
      "1  Programming for Everybody (Getting Started wit...   \n",
      "2            CS50's Introduction to Computer Science   \n",
      "3                                 The Analytics Edge   \n",
      "4  Marketing Analytics: Marketing Measurement Str...   \n",
      "\n",
      "                              University Difficulty Level  \\\n",
      "0                                    edX         Beginner   \n",
      "1             The University of Michigan         Beginner   \n",
      "2                     Harvard University         Beginner   \n",
      "3  Massachusetts Institute of Technology     Intermediate   \n",
      "4     University of California, Berkeley         Beginner   \n",
      "\n",
      "                                                Link  \\\n",
      "0     https://www.edx.org/course/how-to-learn-online   \n",
      "1  https://www.edx.org/course/programming-for-eve...   \n",
      "2  https://www.edx.org/course/cs50s-introduction-...   \n",
      "3      https://www.edx.org/course/the-analytics-edge   \n",
      "4  https://www.edx.org/course/marketing-analytics...   \n",
      "\n",
      "                                               About  \\\n",
      "0  Learn essential strategies for successful onli...   \n",
      "1  This course is a \"no prerequisite\" introductio...   \n",
      "2  An introduction to the intellectual enterprise...   \n",
      "3  Through inspiring examples and stories, discov...   \n",
      "4     This course is part of a MicroMastersÂ® Program   \n",
      "\n",
      "                                  Course Description  \n",
      "0  Designed for those who are new to elearning, t...  \n",
      "1  This course aims to teach everyone the basics ...  \n",
      "2  This is CS50x , Harvard University's introduct...  \n",
      "3  In the last decade, the amount of data availab...  \n",
      "4  Begin your journey in a new career in marketin...  \n"
     ]
    }
   ],
   "source": [
    "# Read the CSV file.\n",
    "df = pd.read_csv(\"Edx.csv\")\n",
    "print(\"Original Data Sample:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the relevant columns into course_data.\n",
    "course_data = df[['Name', 'About', 'Course Description']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SOK Chanda\\AppData\\Local\\Temp\\ipykernel_22628\\2847646851.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  course_data['Name'] = course_data['Name'].fillna(\"\")\n",
      "C:\\Users\\SOK Chanda\\AppData\\Local\\Temp\\ipykernel_22628\\2847646851.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  course_data['About'] = course_data['About'].fillna(\"\")\n",
      "C:\\Users\\SOK Chanda\\AppData\\Local\\Temp\\ipykernel_22628\\2847646851.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  course_data['Course Description'] = course_data['Course Description'].fillna(\"\")\n"
     ]
    }
   ],
   "source": [
    "# Fill missing values.\n",
    "course_data['Name'] = course_data['Name'].fillna(\"\")\n",
    "course_data['About'] = course_data['About'].fillna(\"\")\n",
    "course_data['Course Description'] = course_data['Course Description'].fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available paths: ['C:\\\\Users\\\\SOK Chanda/nltk_data', 'c:\\\\Python312\\\\nltk_data', 'c:\\\\Python312\\\\share\\\\nltk_data', 'c:\\\\Python312\\\\lib\\\\nltk_data', 'C:\\\\Users\\\\SOK Chanda\\\\AppData\\\\Roaming\\\\nltk_data', 'C:\\\\nltk_data', 'D:\\\\nltk_data', 'E:\\\\nltk_data', 'C:/nltk_data']\n",
      "['a', 'about', 'above', 'after', 'again', 'against', 'ain', 'all', 'am', 'an']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to C:/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "os.environ['NLTK_DATA'] = 'C:/nltk_data'\n",
    "# Ensure that required NLTK datasets are downloaded to a specific directory.\n",
    "nltk.download('punkt', download_dir='C:/nltk_data')\n",
    "nltk.download('punkt_tab', download_dir='C:/nltk_data')\n",
    "nltk.download('stopwords', download_dir='C:/nltk_data')\n",
    "nltk.download('wordnet', download_dir='C:/nltk_data')\n",
    "nltk.data.path.append(\"C:/nltk_data\")\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "if \"C:/nltk_data\" not in nltk.data.path:\n",
    "    nltk.data.path.append(\"C:/nltk_data\")\n",
    "\n",
    "print(\"Available paths:\", nltk.data.path)\n",
    "print(stopwords.words('english')[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the preprocessing function.\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = str(text)\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    text = re.sub(f'[{re.escape(string.punctuation)}]', '', text)\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Original: How to Learn Online\n",
      "Sample Processed: ['learn', 'online']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SOK Chanda\\AppData\\Local\\Temp\\ipykernel_22628\\3402202032.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  course_data['title_tokens'] = course_data['Name'].astype(str).apply(preprocess_text)\n",
      "C:\\Users\\SOK Chanda\\AppData\\Local\\Temp\\ipykernel_22628\\3402202032.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  course_data['about_tokens'] = course_data['About'].astype(str).apply(preprocess_text)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed Data Sample:\n",
      "                                        title_tokens  \\\n",
      "0                                    [learn, online]   \n",
      "1  [programming, everybody, getting, started, pyt...   \n",
      "2              [cs, introduction, computer, science]   \n",
      "3                                  [analytics, edge]   \n",
      "4  [marketing, analytics, marketing, measurement,...   \n",
      "\n",
      "                                        about_tokens  \\\n",
      "0  [learn, essential, strategy, successful, onlin...   \n",
      "1  [course, prerequisite, introduction, python, p...   \n",
      "2  [introduction, intellectual, enterprise, compu...   \n",
      "3  [inspiring, example, story, discover, power, d...   \n",
      "4             [course, part, micromastersÂ®, program]   \n",
      "\n",
      "                                  description_tokens  \n",
      "0  [designed, new, elearning, course, prepare, st...  \n",
      "1  [course, aim, teach, everyone, basic, programm...  \n",
      "2  [csx, harvard, university, introduction, intel...  \n",
      "3  [last, decade, amount, data, available, organi...  \n",
      "4  [begin, journey, new, career, marketing, analy...  \n",
      "\n",
      "Processed data exported to Edx_processed.csv\n"
     ]
    }
   ],
   "source": [
    "# Test the preprocessing function on a sample value.\n",
    "sample_value = course_data['Name'].iloc[0]\n",
    "print(\"Sample Original:\", sample_value)\n",
    "\n",
    "print(\"Sample Processed:\", preprocess_text(sample_value))\n",
    "\n",
    "# Apply preprocessing and save results in new columns.\n",
    "course_data['title_tokens'] = course_data['Name'].astype(str).apply(preprocess_text)\n",
    "course_data['about_tokens'] = course_data['About'].astype(str).apply(preprocess_text)\n",
    "course_data['description_tokens'] = course_data['Course Description'].astype(str).apply(preprocess_text)\n",
    "\n",
    "print(\"\\nProcessed Data Sample:\")\n",
    "print(course_data[['title_tokens', 'about_tokens', 'description_tokens']].head())\n",
    "\n",
    "# Export the processed data to a new CSV file.\n",
    "course_data.to_csv(\"convert_Edx_processed.csv\", index=False)\n",
    "print(\"\\nProcessed data exported to Edx_processed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data Sample:\n",
      "                                                Name  \\\n",
      "0                                How to Learn Online   \n",
      "1  Programming for Everybody (Getting Started wit...   \n",
      "2            CS50's Introduction to Computer Science   \n",
      "3                                 The Analytics Edge   \n",
      "4  Marketing Analytics: Marketing Measurement Str...   \n",
      "\n",
      "                                               About  \\\n",
      "0  Learn essential strategies for successful onli...   \n",
      "1  This course is a \"no prerequisite\" introductio...   \n",
      "2  An introduction to the intellectual enterprise...   \n",
      "3  Through inspiring examples and stories, discov...   \n",
      "4     This course is part of a MicroMastersÂ® Program   \n",
      "\n",
      "                                  Course Description  \\\n",
      "0  Designed for those who are new to elearning, t...   \n",
      "1  This course aims to teach everyone the basics ...   \n",
      "2  This is CS50x , Harvard University's introduct...   \n",
      "3  In the last decade, the amount of data availab...   \n",
      "4  Begin your journey in a new career in marketin...   \n",
      "\n",
      "                                        title_tokens  \\\n",
      "0                                ['learn', 'online']   \n",
      "1  ['programming', 'everybody', 'getting', 'start...   \n",
      "2      ['cs', 'introduction', 'computer', 'science']   \n",
      "3                              ['analytics', 'edge']   \n",
      "4  ['marketing', 'analytics', 'marketing', 'measu...   \n",
      "\n",
      "                                        about_tokens  \\\n",
      "0  ['learn', 'essential', 'strategy', 'successful...   \n",
      "1  ['course', 'prerequisite', 'introduction', 'py...   \n",
      "2  ['introduction', 'intellectual', 'enterprise',...   \n",
      "3  ['inspiring', 'example', 'story', 'discover', ...   \n",
      "4     ['course', 'part', 'micromastersÂ®', 'program']   \n",
      "\n",
      "                                  description_tokens  \n",
      "0  ['designed', 'new', 'elearning', 'course', 'pr...  \n",
      "1  ['course', 'aim', 'teach', 'everyone', 'basic'...  \n",
      "2  ['csx', 'harvard', 'university', 'introduction...  \n",
      "3  ['last', 'decade', 'amount', 'data', 'availabl...  \n",
      "4  ['begin', 'journey', 'new', 'career', 'marketi...  \n"
     ]
    }
   ],
   "source": [
    "# Read the CSV file.\n",
    "convert_df = pd.read_csv(\"convert_Edx_processed.csv\")\n",
    "print(\"Original Data Sample:\")\n",
    "print(convert_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name                  0\n",
       "About                 0\n",
       "Course Description    0\n",
       "title_tokens          0\n",
       "about_tokens          0\n",
       "description_tokens    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To check for the missing values\n",
    "convert_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 720 entries, 0 to 719\n",
      "Data columns (total 6 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   Name                720 non-null    object\n",
      " 1   About               720 non-null    object\n",
      " 2   Course Description  720 non-null    object\n",
      " 3   title_tokens        720 non-null    object\n",
      " 4   about_tokens        720 non-null    object\n",
      " 5   description_tokens  720 non-null    object\n",
      "dtypes: object(6)\n",
      "memory usage: 33.9+ KB\n"
     ]
    }
   ],
   "source": [
    "convert_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate Row(s):\n",
      "                           Name  \\\n",
      "80  Introduction to Probability   \n",
      "\n",
      "                                                About  \\\n",
      "80  Learn probability, an essential language and s...   \n",
      "\n",
      "                                   Course Description  \\\n",
      "80  Probability and statistics help to bring logic...   \n",
      "\n",
      "                       title_tokens  \\\n",
      "80  ['introduction', 'probability']   \n",
      "\n",
      "                                         about_tokens  \\\n",
      "80  ['learn', 'probability', 'essential', 'languag...   \n",
      "\n",
      "                                   description_tokens  \n",
      "80  ['probability', 'statistic', 'help', 'bring', ...  \n"
     ]
    }
   ],
   "source": [
    "duplicates = convert_df[convert_df.duplicated()]\n",
    "print(\"Duplicate Row(s):\")\n",
    "print(duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count     720.000000\n",
      "mean      184.320833\n",
      "std       112.856087\n",
      "min        25.000000\n",
      "25%       118.750000\n",
      "50%       167.000000\n",
      "75%       223.000000\n",
      "max      1537.000000\n",
      "Name: description_length, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "convert_df['description_length'] = convert_df['Course Description'].apply(lambda x: len(str(x).split()))\n",
    "print(convert_df['description_length'].describe())  # Check min, max, mean length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_df = convert_df[convert_df['description_length'] > 5]  # Keep meaningful descriptions\n",
    "convert_df['Course Description'] = convert_df['Course Description'].apply(lambda x: ' '.join(str(x).split()[:500]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    text = str(text)\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)  # Remove special characters\n",
    "    return text\n",
    "\n",
    "convert_df['Course Description'] = convert_df['Course Description'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_df['Course Description'] = convert_df['Course Description'].str.lower().str.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â Cleaned data saved successfully!\n"
     ]
    }
   ],
   "source": [
    "course_data.to_csv(\"cleaned_Edx_data.csv\", index=False)\n",
    "print(\"â Cleaned data saved successfully!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
